For source: 10.1016&sol;j.ijrmhm.2016.02.006.html
Traceback (most recent call last):
  File "/Users/pastalover/Projects/sisyphus_context/sisyphus/heas/extract_lc.py", line 183, in extract_bulk
    records = chain.invoke({'paper': para_extend.page_content, 'instruction': construct_instruction(synthesis_instr)}).records
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/langchain_core/runnables/base.py", line 3022, in invoke
    input = context.run(step.invoke, input, config)
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/langchain_core/runnables/base.py", line 5352, in invoke
    return self.bound.invoke(
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/langchain_openai/chat_models/base.py", line 677, in _generate
    response = self.root_client.beta.chat.completions.parse(**payload)
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/openai/resources/beta/chat/completions.py", line 156, in parse
    return self._post(
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/openai/_base_client.py", line 1280, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/openai/_base_client.py", line 957, in request
    return self._request(
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/openai/_base_client.py", line 1063, in _request
    return self._process_response(
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/openai/_base_client.py", line 1162, in _process_response
    return api_response.parse()
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/openai/_response.py", line 319, in parse
    parsed = self._options.post_parser(parsed)
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/openai/resources/beta/chat/completions.py", line 150, in parser
    return _parse_chat_completion(
  File "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/openai/lib/_parsing/_completions.py", line 72, in parse_chat_completion
    raise LengthFinishReasonError(completion=chat_completion)
openai.LengthFinishReasonError: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=15000, prompt_tokens=9902, total_tokens=24902, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=1024))
