{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045d89aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mInitializing Langtrace SDK..\u001b[39m\n",
      "\u001b[37m⭐ Leave our github a star to stay on top of our updates - https://github.com/Scale3-Labs/langtrace\u001b[39m\n",
      "Skipping openai due to error while instrumenting: No module named 'openai.resources.responses'\n",
      "\u001b[34mExporting spans to Extraction..\u001b[39m\n",
      "\u001b[34mLangtrace Project URL: https://app.langtrace.ai/project/cmf58kthl000f5i55fmxndtpw/traces\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Must precede any llm module imports\n",
    "from langtrace_python_sdk import langtrace\n",
    "langtrace.init(api_key = '8e0dafdc118df1613b10dbdda776b0b062427b0a9b1cb18b719688714e1ea445',\n",
    "  disable_tracing_for_functions= {\n",
    "    \"open_ai\": [ # All supported functions for openai\n",
    "      'openai.embeddings.create',\n",
    "    ]\n",
    "  },\n",
    "  disable_instrumentations={\"all_except\": ['openai']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab75e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from ast import literal_eval\n",
    "from typing import Optional, Literal\n",
    "from functools import partial\n",
    "\n",
    "import dspy\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from sisyphus.heas.label import label_paras\n",
    "from sisyphus.chain.paragraph import Paragraph, ParagraphExtend\n",
    "from sisyphus.chain import Filter, Writer\n",
    "from sisyphus.strategy.run_strategy import ExtractStrategy\n",
    "from sisyphus.strategy.pydantic_models_general import Processing, Material, MaterialDescriptionBase\n",
    "from sisyphus.strategy.utils import get_paras_with_props, get_synthesis_paras\n",
    "from sisyphus.heas.prompt import *\n",
    "from sisyphus.utils.helper_functions import get_plain_articledb, get_create_resultdb\n",
    "from sisyphus.heas.synthesis import get_synthesis_prompt\n",
    "from sisyphus.strategy.llm_models import categorize_agent\n",
    "\n",
    "\n",
    "lm = dspy.LM('openai/gpt-4.1-mini')\n",
    "dspy.configure(lm=lm)\n",
    "chat_model = ChatOpenAI(model='gpt-4.1-mini')\n",
    "\n",
    "class Strength(BaseModel):\n",
    "    \"\"\"Tensile/Compressive test results\"\"\"\n",
    "    ys: Optional[str] = Field(description=\"Yield strength with unit\")\n",
    "    uts: Optional[str] = Field(description=\"Ultimate tensile/compressive strength with unit\")\n",
    "    strain: Optional[str] = Field(description=\"Fracture strain. If in percentage form, please add '%' sign, else return as decimal form. Example: 0.5 or 50%\")\n",
    "    temperature: Optional[str] = Field(description=\"Test temperature with unit, if not specified, return 'room temperature'\")\n",
    "    strain_rate: Optional[str] = Field(description=\"Strain rate with unit\")\n",
    "    test_type: Literal['tensile', 'compressive']\n",
    "\n",
    "\n",
    "class Phase(BaseModel):\n",
    "    \"\"\"Phase information\"\"\"\n",
    "    phases: list[str] = Field(description=\"List of phases present in the material\")\n",
    "\n",
    "class Processing(BaseModel):\n",
    "    \"\"\"Processing route for a material\n",
    "    Return field steps as '[]' if you cannot find any. For fields with unknown value, filled with empty string\"\"\"\n",
    "    steps: str = Field(description=\"\"\"List of processing steps in chronological order, form them as json object. For example: [{\"induction melting\": {\"temperature\": \"1500 K\"}}, {\"annealed\": {\"temperature\": \"800 K\", \"duration\": \"1h\"}}]\"\"\")\n",
    "\n",
    "    @field_validator('steps', mode='after')\n",
    "    @classmethod\n",
    "    def load(cls, value: str):\n",
    "        try:\n",
    "            value = json.loads(value)\n",
    "        except:\n",
    "            value = literal_eval(value)\n",
    "        return value\n",
    "\n",
    "prompt_config = \\\n",
    "    {\n",
    "        'strength': (EXTRACT_PROPERTY_SYS_GENERIC_PROMPT, STRENGTH_PROMPT),\n",
    "        'phase': (EXTRACT_PROPERTY_SYS_GENERIC_PROMPT, PHASE_PROMPT),\n",
    "        'synthesis': (EXTRACT_PROCESS_SYS_GENERIC_PROMPT, PROCESS_PROMPT)\n",
    "    }\n",
    "\n",
    "def reconstr_c(paragraphs):\n",
    "    p_exp = get_synthesis_paras(paragraphs) + get_paras_with_props(paragraphs, 'composition')\n",
    "    p_str_paras = get_paras_with_props(paragraphs, 'strength') + get_paras_with_props(paragraphs, 'strain_rate')\n",
    "    p_phase_paras = get_paras_with_props(paragraphs, 'phase')\n",
    "    # Include synthesis paragraphs for context if available\n",
    "    p_str = ParagraphExtend.from_paragraphs(p_str_paras + p_exp, type='strength') if p_str_paras else None\n",
    "    p_phase = ParagraphExtend.from_paragraphs(p_phase_paras + p_exp, type='phase') if p_phase_paras else None\n",
    "    p_exp_final = ParagraphExtend.from_paragraphs(p_exp, type='synthesis') if p_exp else None\n",
    "    return {\n",
    "        \"strength\": p_str,\n",
    "        \"phase\": p_phase,\n",
    "        \"synthesis\": p_exp_final\n",
    "    }\n",
    "\n",
    "models_d = {\n",
    "    'strength': Strength,\n",
    "    'phase': Phase,\n",
    "    'synthesis': Processing\n",
    "}\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195a65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from sisyphus.utils.helper_functions import get_title_abs, render_docs\n",
    "\n",
    "class ClassifyPaper(dspy.Signature):\n",
    "    \"\"\"assign label to HEAs (high entropy alloys) paper based on their title and abstract.\"\"\"\n",
    "    context: str = dspy.InputField(desc='Title and abstract of the paper')\n",
    "    label: Literal['hea_experimental', 'hea_theoretical', 'irrelevant'] = dspy.OutputField(desc=\"Pay attention to keywords such as 'molecular dynamics' or 'machine learning,' which should be labeled as hea_theoretical. Label keywords related to fabrication processes as hea_experimental.\")\n",
    "    mechanical_relevancy: bool = dspy.OutputField(desc='whether this paper describe the mechanical properties such as tensile or compressive')\n",
    "classifier_paper = dspy.ChainOfThought(signature=ClassifyPaper)\n",
    "\n",
    "def paper_filter(docs):\n",
    "    title, abstract = get_title_abs(docs)\n",
    "    prediction = classifier_paper(context=render_docs(abstract, title))\n",
    "    if prediction.label == 'hea_experimental' and prediction.mechanical_relevancy:\n",
    "        return docs\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0803fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/pydantic/main.py:1552: RuntimeWarning: fields may not start with an underscore, ignoring \"__tablename__\"\n",
      "  warnings.warn(f'fields may not start with an underscore, ignoring \"{f_name}\"', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "es = ExtractStrategy(\n",
    "    reconstruct_paragraph_context_func=reconstr_c,\n",
    "    formatted_func=get_synthesis_prompt,\n",
    "    pydantic_models_dict=models_d,\n",
    "    save_to='op.jsonl'\n",
    ")\n",
    "es.build(prompt_config=prompt_config, chat_model=chat_model)\n",
    "db = get_plain_articledb('heas_1531')\n",
    "getter = Filter(db)\n",
    "result_db = get_create_resultdb('context_isolated')\n",
    "writer = Writer(result_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bcaa623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sisyphus.chain.chain_elements import run_chains_with_extarction_history_multi_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8237b354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:13<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# LABEL\n",
    "labeled_database = get_plain_articledb('heas_labeled_extend')\n",
    "labeled_database.create_db()\n",
    "def save(paras):\n",
    "    labeled_database.dump_state(paras)\n",
    "label_chain = getter + paper_filter + label_paras + save\n",
    "# run_chains_with_extarction_history_multi_threads(label_chain, 'heas_test', 5, 'heas_labeled_extend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebddeb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_db.clear_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7bc968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "labeled_getter = Filter(labeled_database)\n",
    "def load(docs):\n",
    "    return [Paragraph.from_labeled_document(doc, id_) for id_, doc in enumerate(docs)]\n",
    "extract_chain = labeled_getter + load + es + writer\n",
    "extract_chain.compose('10.1002&sol;adem.201900587.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9078b39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "get_paras_chain = labeled_getter + load\n",
    "paras = get_paras_chain.compose('10.1002&sol;adem.201900587.html')\n",
    "ps = get_paras_with_props(paras, 'phase')\n",
    "for p in ps:\n",
    "    print(p.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556cb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = getter + paper_filter + label_paras + es + writer\n",
    "# # run_chains_with_extarction_history_multi_threads(chain, 'heas_test', 5, 'context_isolated', 5)\n",
    "# chain.compose('10.1002&sol;adem.201900587.html')\n",
    "# # chain.compose('10.1016&sol;j.ijrmhm.2023.106163.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sisyphus_context",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
