{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045d89aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mInitializing Langtrace SDK..\u001b[39m\n",
      "\u001b[37m⭐ Leave our github a star to stay on top of our updates - https://github.com/Scale3-Labs/langtrace\u001b[39m\n",
      "Skipping openai due to error while instrumenting: No module named 'openai.resources.responses'\n",
      "\u001b[34mExporting spans to Extraction..\u001b[39m\n",
      "\u001b[34mLangtrace Project URL: https://app.langtrace.ai/project/cmf58kthl000f5i55fmxndtpw/traces\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "# Must precede any llm module imports\n",
    "\n",
    "from langtrace_python_sdk import langtrace\n",
    "langtrace.init(api_key = '8e0dafdc118df1613b10dbdda776b0b062427b0a9b1cb18b719688714e1ea445',\n",
    "  disable_tracing_for_functions= {\n",
    "    \"open_ai\": [ # All supported functions for openai\n",
    "      'openai.embeddings.create',\n",
    "    ]\n",
    "  },\n",
    "  disable_instrumentations={\"all_except\": ['openai']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab75e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ast import literal_eval\n",
    "from typing import Optional\n",
    "from functools import partial\n",
    "\n",
    "import dspy\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from sisyphus.heas.label import label_paras\n",
    "from sisyphus.chain.paragraph import Paragraph, ParagraphExtend\n",
    "from sisyphus.chain import Filter, Writer\n",
    "from sisyphus.strategy.run_strategy import ExtractStrategy\n",
    "from sisyphus.strategy.pydantic_models_general import Processing, Material, MaterialDescriptionBase\n",
    "from sisyphus.strategy.utils import get_paras_with_props, get_synthesis_paras\n",
    "from sisyphus.heas.prompt import *\n",
    "from sisyphus.utils.helper_functions import get_plain_articledb, get_create_resultdb\n",
    "from sisyphus.heas.synthesis import get_synthesis_prompt\n",
    "from sisyphus.strategy.llm_models import categorize_agent\n",
    "\n",
    "\n",
    "lm = dspy.LM('openai/gpt-4.1-mini')\n",
    "dspy.configure(lm=lm)\n",
    "chat_model = ChatOpenAI(model='gpt-4.1-mini')\n",
    "\n",
    "class Strength(BaseModel):\n",
    "    \"\"\"Tensile/Compressive test results\"\"\"\n",
    "    ys: Optional[str] = Field(description=\"Yield strength with unit\")\n",
    "    uts: Optional[str] = Field(description=\"Ultimate tensile/compressive strength with unit\")\n",
    "    strain: Optional[str] = Field(description=\"Fracture strain. If in percentage form, please add '%' sign, else return as decimal form. Example: 0.5 or 50%\")\n",
    "    temperature: Optional[str] = Field(description=\"Test temperature with unit, if not specified, return 'room temperature'\")\n",
    "    strain_rate: Optional[str] = Field(description=\"Strain rate with unit\")\n",
    "    test_type: Literal['tensile', 'compressive']\n",
    "\n",
    "\n",
    "class Phase(BaseModel):\n",
    "    \"\"\"Phase information\"\"\"\n",
    "    phases: list[str] = Field(description=\"List of phases present in the material\")\n",
    "\n",
    "class Processing(BaseModel):\n",
    "    \"\"\"Processing route for a material\n",
    "    Return field steps as '[]' if you cannot find any. For fields with unknown value, filled with empty string\"\"\"\n",
    "    steps: str = Field(description=\"\"\"List of processing steps in chronological order, form them as json object. For example: [{\"induction melting\": {\"temperature\": \"1500 K\"}}, {\"annealed\": {\"temperature\": \"800 K\", \"duration\": \"1h\"}}]\"\"\")\n",
    "\n",
    "    @field_validator('steps', mode='after')\n",
    "    @classmethod\n",
    "    def load(cls, value: str):\n",
    "        try:\n",
    "            value = json.loads(value)\n",
    "        except:\n",
    "            value = literal_eval(value)\n",
    "        return value\n",
    "\n",
    "prompt_config = {\n",
    "    'contextualized': {\n",
    "        'strength': (EXTRACT_PROPERTY_SYS_GENERIC_PROMPT, STRENGTH_PROMPT),\n",
    "        'phase': (EXTRACT_PROPERTY_SYS_GENERIC_PROMPT, PHASE_PROMPT),\n",
    "        'synthesis': (EXTRACT_PROCESS_SYS_GENERIC_PROMPT, PROCESS_PROMPT)\n",
    "    },\n",
    "    'isolated': {\n",
    "        'strength': (EXTRACT_PROPERTY_SYS_GENERIC_PROMPT, STRENGTH_PROMPT),\n",
    "        'phase': (EXTRACT_PROPERTY_SYS_GENERIC_PROMPT, PHASE_PROMPT),\n",
    "        'synthesis': (EXTRACT_PROCESS_SYS_GENERIC_PROMPT, PROCESS_ISOLATED_PROMPT)\n",
    "    }\n",
    "}\n",
    "\n",
    "def reconstr_c(paragraphs):\n",
    "    p_str = ParagraphExtend.from_paragraphs(get_synthesis_paras(paragraphs) + get_paras_with_props(paragraphs, 'strength') + get_paras_with_props(paragraphs, 'strain_rate'), type='strength')\n",
    "    p_phase = ParagraphExtend.from_paragraphs(get_synthesis_paras(paragraphs) + get_paras_with_props(paragraphs, 'phase'), type='phase')\n",
    "    p_exp = ParagraphExtend.from_paragraphs(get_synthesis_paras(paragraphs) + get_paras_with_props(paragraphs, 'composition'), type='synthesis')\n",
    "    return{\n",
    "        \"strength\": p_str,\n",
    "        \"phase\": p_phase,\n",
    "        \"synthesis\": p_exp\n",
    "    }\n",
    "\n",
    "def reconstr_i(paragraphs):\n",
    "    p_str = ParagraphExtend.from_paragraphs(get_paras_with_props(paragraphs, 'strength') + get_paras_with_props(paragraphs, 'strain_rate'), type='strength')\n",
    "    p_phase = ParagraphExtend.from_paragraphs(get_paras_with_props(paragraphs, 'phase'), type='phase')\n",
    "    p_exp = ParagraphExtend.from_paragraphs(get_synthesis_paras(paragraphs), type='synthesis')\n",
    "    return{\n",
    "        \"strength\": p_str,\n",
    "        \"phase\": p_phase,\n",
    "        \"synthesis\": p_exp\n",
    "    }\n",
    "\n",
    "models_d = {\n",
    "    'strength': Strength,\n",
    "    'phase': Phase,\n",
    "    'synthesis': Processing\n",
    "}\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195a65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from sisyphus.utils.helper_functions import get_title_abs, render_docs\n",
    "\n",
    "class ClassifyPaper(dspy.Signature):\n",
    "    \"\"\"assign label to HEAs (high entropy alloys) paper based on their title and abstract.\"\"\"\n",
    "    context: str = dspy.InputField(desc='Title and abstract of the paper')\n",
    "    label: Literal['hea_experimental', 'hea_theoretical', 'irrelevant'] = dspy.OutputField(desc=\"Pay attention to keywords such as 'molecular dynamics' or 'machine learning,' which should be labeled as hea_theoretical. Label keywords related to fabrication processes as hea_experimental.\")\n",
    "    mechanical_relevancy: bool = dspy.OutputField(desc='whether this paper describe the mechanical properties such as tensile or compressive')\n",
    "classifier_paper = dspy.ChainOfThought(signature=ClassifyPaper)\n",
    "\n",
    "def paper_filter(docs):\n",
    "    title, abstract = get_title_abs(docs)\n",
    "    prediction = classifier_paper(context=render_docs(abstract, title))\n",
    "    if prediction.label == 'hea_experimental' and prediction.mechanical_relevancy:\n",
    "        return docs\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0803fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pastalover/miniconda3/envs/sisyphus_context/lib/python3.10/site-packages/pydantic/main.py:1552: RuntimeWarning: fields may not start with an underscore, ignoring \"__tablename__\"\n",
      "  warnings.warn(f'fields may not start with an underscore, ignoring \"{f_name}\"', RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "es = ExtractStrategy(\n",
    "    reconstruct_paragraph_context_func=reconstr_c,\n",
    "    reconstruct_paragraph_isolate_func=reconstr_i,\n",
    "    formatted_func=get_synthesis_prompt,\n",
    "    categorize_agent=categorize_agent,\n",
    "    pydantic_models_dict=models_d,\n",
    "    save_to='op.jsonl'\n",
    ")\n",
    "es.build(prompt_config=prompt_config, chat_model=chat_model)\n",
    "db = get_plain_articledb('heas_1531')\n",
    "getter = Filter(db)\n",
    "result_db = get_create_resultdb('context_isolated')\n",
    "writer = Writer(result_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2556cb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:33<00:50, 16.99s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "result must be a dict or a pydantic model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msisyphus\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchain_elements\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_chains_with_extarction_history_multi_threads\n\u001b[1;32m      2\u001b[0m chain \u001b[38;5;241m=\u001b[39m getter \u001b[38;5;241m+\u001b[39m paper_filter \u001b[38;5;241m+\u001b[39m label_paras \u001b[38;5;241m+\u001b[39m es \u001b[38;5;241m+\u001b[39m writer\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun_chains_with_extarction_history_multi_threads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheas_test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontext_isolated\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# chain.compose('10.1002&sol;adem.201900587.html')\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/sisyphus_context/sisyphus/chain/chain_elements.py:529\u001b[0m, in \u001b[0;36mrun_chains_with_extarction_history_multi_threads\u001b[0;34m(chain, directory, batch_size, namespace, extract_nums, given_names)\u001b[0m\n\u001b[1;32m    527\u001b[0m futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(runnable, file_name) \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m file_names]\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(as_completed(futures), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(file_names)):\n\u001b[0;32m--> 529\u001b[0m     \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sisyphus_context/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniconda3/envs/sisyphus_context/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sisyphus_context/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Projects/sisyphus_context/sisyphus/chain/database.py:310\u001b[0m, in \u001b[0;36madd_manager_callback.<locals>.wrapper\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(key):\n\u001b[0;32m--> 310\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;241m!=\u001b[39m FAILED:\n\u001b[1;32m    312\u001b[0m         manager\u001b[38;5;241m.\u001b[39mupdate(key)\n",
      "File \u001b[0;32m~/Projects/sisyphus_context/sisyphus/chain/chain_elements.py:440\u001b[0m, in \u001b[0;36mChain.compose\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m    438\u001b[0m origin_input \u001b[38;5;241m=\u001b[39m input_\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, component \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents):\n\u001b[0;32m--> 440\u001b[0m     input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcomponent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_ \u001b[38;5;241m==\u001b[39m FAILED:\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m FAILED\n",
      "File \u001b[0;32m~/Projects/sisyphus_context/sisyphus/chain/chain_elements.py:395\u001b[0m, in \u001b[0;36mWriter.invoke\u001b[0;34m(self, paragraphs)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\u001b[38;5;28mself\u001b[39m, paragraphs: \u001b[38;5;28mlist\u001b[39m[ParagraphExtend]):\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m paragraph \u001b[38;5;129;01min\u001b[39;00m paragraphs:\n\u001b[0;32m--> 395\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparagraph\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/sisyphus_context/sisyphus/chain/chain_elements.py:376\u001b[0m, in \u001b[0;36mWriter.save\u001b[0;34m(self, paragraph)\u001b[0m\n\u001b[1;32m    374\u001b[0m data \u001b[38;5;241m=\u001b[39m paragraph\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparagraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparagraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/sisyphus_context/sisyphus/chain/database.py:206\u001b[0m, in \u001b[0;36mResultDB.save_result\u001b[0;34m(self, text, metadata, results)\u001b[0m\n\u001b[1;32m    204\u001b[0m         result_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mResult(result\u001b[38;5;241m=\u001b[39mresult)\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult must be a dict or a pydantic model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    207\u001b[0m     document\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mappend(result_)\n\u001b[1;32m    208\u001b[0m session\u001b[38;5;241m.\u001b[39madd(document)\n",
      "\u001b[0;31mValueError\u001b[0m: result must be a dict or a pydantic model"
     ]
    }
   ],
   "source": [
    "from sisyphus.chain.chain_elements import run_chains_with_extarction_history_multi_threads\n",
    "chain = getter + paper_filter + label_paras + es + writer\n",
    "run_chains_with_extarction_history_multi_threads(chain, 'heas_test', 5, 'context_isolated', 5)\n",
    "# chain.compose('10.1002&sol;adem.201900587.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8237b354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sisyphus_context",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
